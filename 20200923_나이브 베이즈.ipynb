{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 나이브 베이즈\n",
    "- 베이즈 방법은 최종 결과의 확률 예측을 위해 상당히 많은 속성을 동시에 고려해야 하는 상황에서 가장 잘 작동"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 확률 기초\n",
    "### 결합 확률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 조건부 확률과 베이즈 정리의 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 나이브 베이즈 분류기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라플라스 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 나이브 베이즈 SMS 스팸 분류 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "import pandas as pd\n",
    "smsdata = pd.read_csv('./Data/SMSSpamCollection.txt', sep = '\\t', header = None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 확인 - head()\n",
    "smsdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼명 변경\n",
    "smsdata.columns = ['class', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class                                               text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 프레임 확인\n",
    "smsdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   class   5572 non-null   object\n",
      " 1   text    5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "smsdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4825, 747)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spam과 ham의 개수 확인\n",
    "smsdata[smsdata['class'] == 'ham'].shape[0], smsdata[smsdata['class'] == 'spam'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 구두점 없애기 : 첫 단계로 모든 구두점을 없앤다. String 라이브러리 이용\n",
    "- 단어 토큰화 : 공백을 기준으로 단어들을 문장으로부터 묶음\n",
    "- 단어를 소문자로 변환 : 모든 단어는 소문자로 통일해 중복을 없앰.\n",
    "- 불용어 제거 :\n",
    "- 최소 세 글자 이상 : 세 글자 미만의 단어는 제거한다.(영어기준일듯)\n",
    "- 형태소 처리 : 형태적 어간을 찾는 기법 => 모델의 정확도를 개선할 수 있는 부분\n",
    "- POS 태깅 : 단어에 품사 마크를 붙인다\n",
    "- 표제어 처리 : 흐음 ...... ate가 -> eat으로 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자연어 전처리 모듈 가져오기\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import pandas as pd\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수 정의\n",
    "def preprocessing(text):\n",
    "    text2 = \" \".join(\"\".join([\" \" if ch in string.punctuation else ch for ch in text]).split()) # 단어를 분할한 후, 표준 구두점인지 확인 후 공백으로 대체\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text2) for word in nltk.word_tokenize(sent)] # 공백을 기준으로 단어로 토큰화\n",
    "    tokens = [word.lower() for word in tokens] # 모두 소문자화\n",
    "    stopwds = stopwords.words('english') # 불용어 영어로 설정\n",
    "    tokens = [token for token in tokens if token not in stopwds] # 불용어 처리\n",
    "    tokens = [word for word in tokens if len(word)>=3] # 영어기준에서 3글자 미만인 단어 제거\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(word) for word in tokens] # 형태소 처리를 하여 불필요한 접미어를 제거\n",
    "    tagged_corpus = pos_tag(tokens) # 품사 표시\n",
    "    Noun_tags = ['NN', 'NNP', 'NNPS', 'NNS']\n",
    "    Verb_tags = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    def prat_lemmatize(token, tag):\n",
    "        if tag in Noun_tags:\n",
    "            return lemmatizer.lemmatize(token,'n')\n",
    "        elif tag in Verb_tags:\n",
    "            return lemmatizer.lemmatize(token,'v')\n",
    "        else:\n",
    "            return lemmatizer.lemmatize(token,'n')\n",
    "    pre_proc_text = \" \".join([prat_lemmatize(token, tag) for token, tag in tagged_corpus])\n",
    "    return pre_proc_text\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "smsdata2 = list()\n",
    "for i in smsdata['text']:\n",
    "    smsdata2.append(preprocessing(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 만들기\n",
    "smsdata2 = pd.DataFrame(smsdata2)\n",
    "smsdata2.columns = ['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(smsdata2['text'], smsdata['class'], train_size = 0.7, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3900,), (1672,), (3900,), (1672,))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 분할 상태 확인\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "708                   quit late lar ard anyway wun drivin\n",
       "4338                                   tuesday night real\n",
       "5029                               chase run cross street\n",
       "4921                   say never answer text confirm deni\n",
       "2592                             still work go small hous\n",
       "                              ...                        \n",
       "3772    wlcome back wonder get eaten lion someth noth ...\n",
       "5191                                     sorri call later\n",
       "5226                  prabha soryda reali frm heart sorus\n",
       "5390                                    joke serious tell\n",
       "860                               say somebodi name tampa\n",
       "Name: text, Length: 3900, dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터화 구축\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    min_df = 2,\n",
    "    ngram_range = (1,2),\n",
    "    stop_words = 'english',\n",
    "    max_features = 4000,\n",
    "    strip_accents = 'unicode',\n",
    "    norm = 'l2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터화 시키기\n",
    "x_train_2 = vectorizer.fit_transform(x_train).todense()\n",
    "x_test_2 = vectorizer.transform(x_test).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성 - 나이브 베이즈\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(x_train_2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>3376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>86</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   ham  spam\n",
       "Actual               \n",
       "ham        3376     1\n",
       "spam         86   437"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix - 학습\n",
    "pd.crosstab(y_train, clf.predict(x_train_2), rownames = ['Actual'], colnames = ['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.978"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확도 - 학습\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "round(accuracy_score(y_train, clf.predict(x_train_2)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99      3377\n",
      "        spam       1.00      0.84      0.91       523\n",
      "\n",
      "    accuracy                           0.98      3900\n",
      "   macro avg       0.99      0.92      0.95      3900\n",
      "weighted avg       0.98      0.98      0.98      3900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report - 학습\n",
    "print(classification_report(y_train, clf.predict(x_train_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>1447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>46</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   ham  spam\n",
       "Actual               \n",
       "ham        1447     1\n",
       "spam         46   178"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix - 테스트\n",
    "pd.crosstab(y_test, clf.predict(x_test_2), rownames = ['Actual'], colnames = ['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.972"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확도 - 학습\n",
    "round(accuracy_score(y_test, clf.predict(x_test_2)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.98      1448\n",
      "        spam       0.99      0.79      0.88       224\n",
      "\n",
      "    accuracy                           0.97      1672\n",
      "   macro avg       0.98      0.90      0.93      1672\n",
      "weighted avg       0.97      0.97      0.97      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report - 학습\n",
    "print(classification_report(y_test, clf.predict(x_test_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상위 특징 출력\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "coefs = clf.coef_\n",
    "intercept = clf.intercept_\n",
    "coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-8.71253868295841, '1st love') (-5.489209289541565, 'free')\n",
      "(-8.71253868295841, '2marrow') (-5.78809642049224, 'txt')\n",
      "(-8.71253868295841, '2mrw') (-5.803329669480185, 'text')\n",
      "(-8.71253868295841, '2nd sm') (-5.9028180936217645, 'mobil')\n",
      "(-8.71253868295841, '2waxsto') (-5.984032931450139, 'stop')\n",
      "(-8.71253868295841, '2waxsto wat') (-6.024318300719303, 'repli')\n",
      "(-8.71253868295841, '3rd') (-6.032044809188538, 'claim')\n",
      "(-8.71253868295841, '3rd natur') (-6.119722439707232, 'www')\n",
      "(-8.71253868295841, '4get') (-6.276338276034236, 'tone')\n",
      "(-8.71253868295841, '4th') (-6.283501510132782, 'servic')\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "top_n_coefs = zip(coefs_with_fns[:n], coefs_with_fns[:-(n+1):-1])\n",
    "for (a,b), (c,d) in top_n_coefs:\n",
    "    print((a,b), (c,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
